import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import datetime
import pandas as pd
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from utils.api_handler import YouTubeAPIKeyManager
import isodate

# ã‚¸ãƒ£ãƒ³ãƒ«è¨­å®š
genre_keywords = {
    "ã‚¢ãƒ‹ãƒ¡ãƒ»æ¼«ç”»è§£èª¬":      ["ã‚¢ãƒ‹ãƒ¡è§£èª¬", "ã‚¢ãƒ‹ãƒ¡è€ƒå¯Ÿ", "æ¼«ç”»è§£èª¬", "æ¼«ç”»ã¾ã¨ã‚", "ã‚¢ãƒ‹ãƒ¡éƒ½å¸‚ä¼èª¬", "ã‚¢ãƒ‹ãƒ¡ãƒ©ãƒ³ã‚­ãƒ³ã‚°"],
    "æ˜ ç”»ãƒ»ãƒ‰ãƒ©ãƒè§£èª¬":      ["æ˜ ç”»è§£èª¬", "ãƒ‰ãƒ©ãƒè§£èª¬", "æ˜ ç”»ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ãƒ‰ãƒ©ãƒè€ƒå¯Ÿ", "äºˆå‘Šã¾ã¨ã‚", "æ˜ ç”»ãƒ©ãƒ³ã‚­ãƒ³ã‚°"],
    "ã‚²ãƒ¼ãƒ ãƒ»å®Ÿæ³ãƒ»ã¾ã¨ã‚":  ["ã‚²ãƒ¼ãƒ å®Ÿæ³", "ã‚²ãƒ¼ãƒ ã¾ã¨ã‚", "ã‚²ãƒ¼ãƒ ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ã‚²ãƒ¼ãƒ è§£èª¬", "æœ€æ–°ã‚²ãƒ¼ãƒ æƒ…å ±"],
    "é›‘å­¦ãƒ»éƒ½å¸‚ä¼èª¬":        ["é›‘å­¦", "è±†çŸ¥è­˜", "éƒ½å¸‚ä¼èª¬", "ã†ã‚“ã¡ã", "è£è©±", "æ„å¤–ãªè©±", "ãƒˆãƒªãƒ“ã‚¢"],
    "ã‚†ã£ãã‚Šè§£èª¬":          ["ã‚†ã£ãã‚Šè§£èª¬", "ã‚†ã£ãã‚Šå®Ÿæ³", "ã‚†ã£ãã‚Šã¾ã¨ã‚", "ã‚†ã£ãã‚Šé›‘å­¦", "ã‚†ã£ãã‚Šãƒ©ãƒ³ã‚­ãƒ³ã‚°"],
    "æ­´å²ãƒ»å‰äººãƒ»äº‹ä»¶":      ["æ­´å²è§£èª¬", "æ­´å²ã¾ã¨ã‚", "å‰äººä¼", "äº‹ä»¶è§£èª¬", "æˆ¦äº‰è§£èª¬", "æ™‚äº‹è§£èª¬"],
    "2chãƒ»ãªã‚“Jã¾ã¨ã‚":      ["2chã¾ã¨ã‚", "ãªã‚“Jã¾ã¨ã‚", "ã‚¹ãƒ¬ã¾ã¨ã‚", "ã‚†ã£ãã‚Š2ch", "çˆ†ç¬‘ã‚¹ãƒ¬"],
    "å•†å“ãƒ»å®¶é›»ãƒ¬ãƒ“ãƒ¥ãƒ¼":     ["å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ã‚¬ã‚¸ã‚§ãƒƒãƒˆç´¹ä»‹", "å®¶é›»ãƒ¬ãƒ“ãƒ¥ãƒ¼", "æœ€æ–°å®¶é›»", "è²·ã£ã¦ã‚ˆã‹ã£ãŸ"],
    "ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ»ãƒ™ã‚¹ãƒˆ":      ["ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ã€‡ã€‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ãƒ™ã‚¹ãƒˆ10", "ã¾ã¨ã‚", "æ¯”è¼ƒ"],
    "æ™‚äº‹ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬":     ["ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬", "æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹", "è©±é¡Œã¾ã¨ã‚", "ç¤¾ä¼šå•é¡Œ", "äº‹ä»¶ã¾ã¨ã‚"],
    "æŠ•è³‡ãƒ»ãƒãƒãƒ¼ãƒ»çµŒæ¸ˆ":      ["æŠ•è³‡", "ãŠé‡‘", "ãƒãƒãƒ¼è§£èª¬", "è³‡ç”£é‹ç”¨", "çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹"],
    "ç§‘å­¦ãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼":      ["ç§‘å­¦è§£èª¬", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼è§£èª¬", "å®‡å®™ã®è©±", "æœ€æ–°ç§‘å­¦", "ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ‹ãƒ¥ãƒ¼ã‚¹"],
    "å¥åº·ãƒ»åŒ»ç™‚ãƒ»ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢":  ["å¥åº·è§£èª¬", "åŒ»ç™‚è§£èª¬", "ãƒ€ã‚¤ã‚¨ãƒƒãƒˆçŸ¥è­˜", "ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢", "ç—…æ°—è§£èª¬"],
    "ã‚¹ãƒãƒ¼ãƒ„ã¾ã¨ã‚":          ["ã‚¹ãƒãƒ¼ãƒ„ã¾ã¨ã‚", "è©¦åˆãƒã‚¤ãƒ©ã‚¤ãƒˆ", "ã‚¹ãƒãƒ¼ãƒ„ãƒ‹ãƒ¥ãƒ¼ã‚¹", "ãƒ—ãƒ¬ãƒ¼é›†"],
    "æ–™ç†ãƒ»ãƒ¬ã‚·ãƒ”ã¾ã¨ã‚":      ["æ–™ç†ã¾ã¨ã‚", "ç°¡å˜ãƒ¬ã‚·ãƒ”", "ä½œã‚Šæ–¹ã¾ã¨ã‚", "ãƒ¬ã‚·ãƒ”ãƒ©ãƒ³ã‚­ãƒ³ã‚°"],
    "è‡ªç„¶ãƒ»å‹•ç‰©ãƒ»ç™’ã—":        ["å‹•ç‰©ã¾ã¨ã‚", "ãƒšãƒƒãƒˆå‹•ç”»", "ç™’ã—å‹•ç”»", "è‡ªç„¶ã®æ˜ åƒ", "çµ¶æ™¯é›†"],
    "ãŒã‚‹ã¡ã‚ƒã‚“ç³»ã¾ã¨ã‚":      ["ãŒã‚‹ã¡ã‚ƒã‚“ã¾ã¨ã‚", "ã‚¬ãƒ¼ãƒ«ã‚ºã¡ã‚ƒã‚“ã­ã‚‹ã¾ã¨ã‚", "ãŒã‚‹ã¡ã‚ƒã‚“ãƒˆãƒ”ãƒƒã‚¯", "å¥³ã®æœ¬éŸ³", "å¥³å­ãƒˆãƒ¼ã‚¯", "å¥³æ€§å‘ã‘æ²ç¤ºæ¿"],
    "ã‚¯ã‚¤ã‚ºãƒ»è¬è§£ã":          ["ã‚¯ã‚¤ã‚º", "è¬è§£ã", "é ­ã®ä½“æ“", "ãƒ‘ã‚ºãƒ«", "é›£å•"],
}

CHANNELS_TXT = "data/channels.txt"

def get_youtube(api_key):
    return build("youtube", "v3", developerKey=api_key)

def search_videos(api_manager, keyword, published_after):
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§å‹•ç”»ã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’æŠ½å‡ºï¼ˆå‹•ç”»IDã‚‚ï¼‰"""
    videos = []
    next_page_token = None

    while True:
        try:
            api_key = api_manager.get_valid_key()
            youtube = get_youtube(api_key)
            response = youtube.search().list(
                q=keyword,
                part="id,snippet",
                maxResults=50,
                type="video",
                order="date",
                publishedAfter=published_after,
                pageToken=next_page_token
            ).execute()
        except HttpError as e:
            if e.resp.status == 403 and 'quotaExceeded' in str(e):
                print("ğŸ” APIã‚­ãƒ¼åˆ‡ã‚Šæ›¿ãˆï¼šquotaExceeded")
                api_manager.index = (api_manager.index + 1) % len(api_manager.api_keys)
                continue
            else:
                raise

        for item in response.get("items", []):
            idinfo = item.get("id", {})
            if idinfo.get("kind") == "youtube#video" and "videoId" in idinfo:
                video_id = idinfo["videoId"]
                channel_id = item["snippet"]["channelId"]
                videos.append((video_id, channel_id))
        next_page_token = response.get("nextPageToken")
        if not next_page_token:
            break

    return videos

def get_uploads_playlist_id(api_manager, channel_id):
    """å„ãƒãƒ£ãƒ³ãƒãƒ«ã®uploadsãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆIDå–å¾—"""
    tried_keys = set()
    while True:
        api_key = api_manager.get_valid_key()
        if api_key in tried_keys:
            api_manager.index = (api_manager.index + 1) % len(api_manager.api_keys)
            continue
        youtube = get_youtube(api_key)
        try:
            res = youtube.channels().list(
                part="contentDetails",
                id=channel_id
            ).execute()
            items = res.get('items', [])
            if not items:
                return None
            return items[0]['contentDetails']['relatedPlaylists']['uploads']
        except HttpError as e:
            if e.resp.status == 403 and 'quotaExceeded' in str(e):
                print("ğŸ” get_uploads_playlist_idï¼šAPIã‚­ãƒ¼åˆ‡ã‚Šæ›¿ãˆï¼ˆquotaExceededï¼‰")
                tried_keys.add(api_key)
                api_manager.index = (api_manager.index + 1) % len(api_manager.api_keys)
                continue
            else:
                print(f"âŒ get_uploads_playlist_idã‚¨ãƒ©ãƒ¼ï¼š{e}")
                return None

def get_recent_videos_from_uploads(api_manager, playlist_id, days=30):
    """uploadsãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã‹ã‚‰éå»daysæ—¥ä»¥å†…ã®å‹•ç”»IDãƒªã‚¹ãƒˆå–å¾—"""
    videos = []
    next_page_token = None
    today = datetime.datetime.utcnow()
    threshold = today - datetime.timedelta(days=days)
    while True:
        api_key = api_manager.get_valid_key()
        youtube = get_youtube(api_key)
        try:
            res = youtube.playlistItems().list(
                part="snippet,contentDetails",
                playlistId=playlist_id,
                maxResults=50,
                pageToken=next_page_token
            ).execute()
        except HttpError as e:
            if e.resp.status == 403 and 'quotaExceeded' in str(e):
                print("ğŸ” get_recent_videos_from_uploadsï¼šAPIã‚­ãƒ¼åˆ‡ã‚Šæ›¿ãˆï¼ˆquotaExceededï¼‰")
                api_manager.index = (api_manager.index + 1) % len(api_manager.api_keys)
                continue
            else:
                print(f"âŒ get_recent_videos_from_uploadsã‚¨ãƒ©ãƒ¼ï¼š{e}")
                break

        for item in res.get("items", []):
            vid = item["contentDetails"]["videoId"]
            published_at = item["contentDetails"].get("videoPublishedAt") or item["snippet"].get("publishedAt")
            if not published_at:
                continue
            video_date = datetime.datetime.strptime(published_at, "%Y-%m-%dT%H:%M:%SZ")
            if video_date < threshold:
                return videos  # 30æ—¥ã‚ˆã‚Šå¤ã„ã‚‚ã®ã¯ä»¥é™ã™ã¹ã¦å¤ã„
            videos.append((vid, published_at))
        next_page_token = res.get("nextPageToken")
        if not next_page_token:
            break
    return videos

def get_video_details_bulk(api_manager, video_id_list):
    """å‹•ç”»IDãƒªã‚¹ãƒˆã‚’ä¸€æ‹¬ã§è©³ç´°å–å¾—ï¼ˆæœ€å¤§50ä»¶ãšã¤ï¼‰"""
    results = []
    failed_ids = []
    import isodate
    for i in range(0, len(video_id_list), 50):
        batch = video_id_list[i:i+50]
        tried_keys = set()
        while True:
            if len(tried_keys) >= len(api_manager.api_keys):
                print("âŒ get_video_details_bulkï¼šAPIã‚­ãƒ¼å…¨æ»…")
                failed_ids.extend(batch)
                break
            api_key = api_manager.get_valid_key()
            if api_key in tried_keys:
                api_manager.index = (api_manager.index + 1) % len(api_manager.api_keys)
                continue
            youtube = get_youtube(api_key)
            try:
                response = youtube.videos().list(
                    part="snippet,statistics,contentDetails",
                    id=",".join(batch)
                ).execute()
                got_ids = set()
                for info in response.get("items", []):
                    got_ids.add(info["id"])
                    if "duration" not in info["contentDetails"]:
                        continue
                    duration = isodate.parse_duration(info["contentDetails"]["duration"]).total_seconds()
                    if duration < 190:
                        continue  # 3åˆ†10ç§’æœªæº€ã¯é™¤å¤–ï¼ˆæ—¢å­˜ä»•æ§˜ï¼‰
                    results.append({
                        "å‹•ç”»ID": info["id"],
                        "å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«": info["snippet"]["title"],
                        "æŠ•ç¨¿æ—¥": info["snippet"]["publishedAt"],
                        "å†ç”Ÿæ•°": int(info["statistics"].get("viewCount", 0)),
                        "ã‚µãƒ ãƒã‚¤ãƒ«URL": info["snippet"]["thumbnails"]["high"]["url"],
                        "duration": duration
                    })
                # å–å¾—ã§ããªã‹ã£ãŸIDã‚‚ãƒªã‚¹ãƒˆåŒ–
                notfound = set(batch) - got_ids
                if notfound:
                    failed_ids.extend(list(notfound))
                break  # batchæˆåŠŸã—ãŸã‚‰æ¬¡ã¸
            except HttpError as e:
                if e.resp.status == 403 and 'quotaExceeded' in str(e):
                    print("ğŸ” get_video_details_bulkï¼šAPIã‚­ãƒ¼åˆ‡ã‚Šæ›¿ãˆï¼ˆquotaExceededï¼‰")
                    tried_keys.add(api_key)
                    api_manager.index = (api_manager.index + 1) % len(api_manager.api_keys)
                    continue
                else:
                    print(f"âŒ get_video_details_bulkã‚¨ãƒ©ãƒ¼ï¼š{e}")
                    failed_ids.extend(batch)
                    break
    return results, failed_ids

def get_channel_details(api_manager, channel_id):
    """ãƒãƒ£ãƒ³ãƒãƒ«åãƒ»ç™»éŒ²è€…æ•°ã‚’å–å¾—"""
    tried_keys = set()
    while True:
        api_key = api_manager.get_valid_key()
        if api_key in tried_keys:
            api_manager.index = (api_manager.index + 1) % len(api_manager.api_keys)
            continue
        youtube = get_youtube(api_key)
        try:
            response = youtube.channels().list(
                part="snippet,statistics",
                id=channel_id
            ).execute()
            items = response.get("items", [])
            if not items:
                return None
            info = items[0]
            return {
                "ãƒãƒ£ãƒ³ãƒãƒ«ID": channel_id,
                "ãƒãƒ£ãƒ³ãƒãƒ«å": info["snippet"]["title"],
                "ç™»éŒ²è€…æ•°": int(info["statistics"].get("subscriberCount", 0))
            }
        except HttpError as e:
            if e.resp.status == 403 and 'quotaExceeded' in str(e):
                print("ğŸ” get_channel_detailsï¼šAPIã‚­ãƒ¼åˆ‡ã‚Šæ›¿ãˆï¼ˆquotaExceededï¼‰")
                tried_keys.add(api_key)
                api_manager.index = (api_manager.index + 1) % len(api_manager.api_keys)
                continue
            else:
                print(f"âŒ get_channel_detailsã‚¨ãƒ©ãƒ¼ï¼š{e}")
                return None

def main():
    print("â–¶ï¸ å‡¦ç†é–‹å§‹ã—ã¾ã—ãŸ")

    api_manager = YouTubeAPIKeyManager("api_keys.txt")
    today = datetime.datetime.utcnow()
    published_after = (today - datetime.timedelta(days=30)).isoformat("T") + "Z"

    all_data = []
    history_data = []
    os.makedirs("data", exist_ok=True)

    for genre, keywords in genre_keywords.items():
        print(f"\nğŸ¯ ã‚¸ãƒ£ãƒ³ãƒ«å‡¦ç†ä¸­: {genre}")

        # â‘  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§å¯¾è±¡ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’ç™ºæ˜ï¼ˆsetå‹ã§é‡è¤‡æ’é™¤ï¼‰
        channel_id_set = set()
        for kw in keywords:
            print(f"ğŸ”‘ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: {kw}")
            results = search_videos(api_manager, kw, published_after)
            for _, channel_id in results:
                channel_id_set.add(channel_id)
        print(f"ğŸ” ç™ºè¦‹ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {len(channel_id_set)}")

        # channels.txtä¿å­˜ï¼ˆæ¯å›ä½œã‚Šç›´ã—ã€æ¬¡å›ä»¥é™æµç”¨å¯ï¼‰
        with open(CHANNELS_TXT, "w", encoding="utf-8") as f:
            for cid in channel_id_set:
                f.write(f"{cid}\n")

        # â‘¡ å„ãƒãƒ£ãƒ³ãƒãƒ«IDã”ã¨ã«ã€Œéå»30æ—¥æŠ•ç¨¿ã®å…¨å‹•ç”»ã€é›†è¨ˆ
        for channel_idx, channel_id in enumerate(channel_id_set, 1):
            print(f"\nğŸ“º [{channel_idx}/{len(channel_id_set)}] ãƒãƒ£ãƒ³ãƒãƒ«å‡¦ç†ä¸­: {channel_id}")

            channel_info = get_channel_details(api_manager, channel_id)
            if not channel_info:
                continue

            # ã“ã“ï¼ç™»éŒ²è€…æ•°2000äººä»¥ä¸‹ã‚’é™¤å¤–
            if channel_info["ç™»éŒ²è€…æ•°"] <= 2000:
                print(f"â­ï¸ ç™»éŒ²è€…æ•°2000äººä»¥ä¸‹ã®ãŸã‚é™¤å¤–: {channel_id} ({channel_info['ç™»éŒ²è€…æ•°']}äºº)")
                continue

            uploads_id = get_uploads_playlist_id(api_manager, channel_id)
            if not uploads_id:
                continue

            recent_videos = get_recent_videos_from_uploads(api_manager, uploads_id, days=30)
            print(f"â–¶ï¸  éå»30æ—¥æŠ•ç¨¿å‹•ç”»æ•°: {len(recent_videos)}")
            video_ids = [vid for vid, _ in recent_videos]

            # bulkã§è©³ç´°å–å¾—
            video_infos, failed_ids = get_video_details_bulk(api_manager, video_ids)
            if failed_ids:
                print(f"âš ï¸ {len(failed_ids)}æœ¬ã®å‹•ç”»è©³ç´°å–å¾—ã«å¤±æ•—: {failed_ids}")

            valid_videos = [v for v in video_infos if v]
            long_videos = [v for v in valid_videos if v["duration"] >= 300]
            if len(valid_videos) == 0 or len(long_videos) < len(valid_videos) * 0.6:
                print(f"âš ï¸ ãƒãƒ£ãƒ³ãƒãƒ«é™¤å¤–ï¼ˆé•·å°ºæ¯”ç‡ < 60%ï¼‰: {channel_id}")
                continue

            # ã€è¿½åŠ ã€‘ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ï¼ˆduration < 60ç§’ï¼‰ã¯ãƒˆãƒ¬ãƒ³ãƒ‰å‹•ç”»å€™è£œã‹ã‚‰é™¤å¤–
            trend_candidates = [v for v in valid_videos if v["duration"] >= 60]
            if not trend_candidates:
                print(f"âš ï¸ ãƒˆãƒ¬ãƒ³ãƒ‰å€™è£œãŒå­˜åœ¨ã—ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {channel_id}")
                continue

            # å†ç”Ÿæ•°æœ€å¤§ã®å‹•ç”»ã‚’ãƒˆãƒ¬ãƒ³ãƒ‰å‹•ç”»ã¨ã™ã‚‹
            trend_video = max(trend_candidates, key=lambda v: v["å†ç”Ÿæ•°"])

            total_views = sum(v["å†ç”Ÿæ•°"] for v in valid_videos)
            group = "5ä¸‡äººä»¥ä¸Š" if channel_info["ç™»éŒ²è€…æ•°"] >= 50000 else "5ä¸‡äººæœªæº€"

            all_data.append({
                "ã‚¸ãƒ£ãƒ³ãƒ«": genre,
                "ãƒãƒ£ãƒ³ãƒãƒ«ID": channel_id,
                "ãƒãƒ£ãƒ³ãƒãƒ«å": channel_info["ãƒãƒ£ãƒ³ãƒãƒ«å"],
                "ç™»éŒ²è€…æ•°": channel_info["ç™»éŒ²è€…æ•°"],
                "ã‚°ãƒ«ãƒ¼ãƒ—": group,
                "éå»30æ—¥å†ç”Ÿæ•°": total_views,
                "ãƒˆãƒ¬ãƒ³ãƒ‰å‹•ç”»ID": trend_video["å‹•ç”»ID"],
                "ãƒˆãƒ¬ãƒ³ãƒ‰å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«": trend_video["å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«"],
                "ãƒˆãƒ¬ãƒ³ãƒ‰æŠ•ç¨¿æ—¥": trend_video["æŠ•ç¨¿æ—¥"][:10],
                "ãƒˆãƒ¬ãƒ³ãƒ‰å‹•ç”»å†ç”Ÿæ•°": trend_video["å†ç”Ÿæ•°"],
                "ã‚µãƒ ãƒã‚¤ãƒ«URL": trend_video["ã‚µãƒ ãƒã‚¤ãƒ«URL"]
            })

            history_data.append({
                "æ—¥ä»˜": today.strftime("%Y-%m-%d"),
                "å‹•ç”»ID": trend_video["å‹•ç”»ID"],
                "å†ç”Ÿæ•°": trend_video["å†ç”Ÿæ•°"]
            })

    df_all = pd.DataFrame(all_data)

    df_top = (
        df_all
        .groupby(["ã‚¸ãƒ£ãƒ³ãƒ«", "ã‚°ãƒ«ãƒ¼ãƒ—"], group_keys=False)
        .apply(lambda x: x.sort_values("éå»30æ—¥å†ç”Ÿæ•°", ascending=False).head(20))
        .reset_index(drop=True)
    )

    os.makedirs("data", exist_ok=True)
    df_top.to_csv("data/channel_video_data.csv", index=False, encoding="utf-8-sig")

    history_path = "data/video_history.csv"
    df_hist = pd.DataFrame(history_data)
    if os.path.exists(history_path):
        df_hist.to_csv(history_path, mode="a", header=False, index=False, encoding="utf-8-sig")
    else:
        df_hist.to_csv(history_path, index=False, encoding="utf-8-sig")

    print("\nâœ… ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†")

if __name__ == "__main__":
    main()
